{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Use a pre-trained network with transfer learning\r\n",
    "\r\n",
    "Training CNNs can take a lot of time, and a lot of data is required for that task. However, much of time is spent to learn the best low-level filters that a network is using to extract patterns from images. A natural question arises - can we use a neural network trained on one dataset and adapt it to classifying different images without full training process? \r\n",
    "\r\n",
    "This approach is called **transfer learning**, beacause we transfer some knowledge from one neural network model to another. In transfer learning, we typically start with a pre-trained model, which has been trained on some large image dataset, sush as **ImageNet**. Those models can already do a good job extracting different features from generic images, and in many case just building a classifier on top of those extracted features can yield a good result. \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch \r\n",
    "import torch.nn as nn \r\n",
    "import torchvision\r\n",
    "from torchvision import transforms\r\n",
    "from torchinfo import summary\r\n",
    "import numpy as np \r\n",
    "import json\r\n",
    "import requests\r\n",
    "\r\n",
    "import os \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import zipfile"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cats vs. Dogs Dataset\r\n",
    "\r\n",
    "In this unit, we will solve a real-life problem of classifying images of cats and dogs. For this reason, we will use [Kaggle Cats vs. Dogs Dataset](https://www.kaggle.com/c/dogs-vs-cats), which can also be downloaded [from Microsoft](https://www.microsoft.com/en-us/download/details.aspx?id=54765).\r\n",
    "\r\n",
    "Let's download this dataset and extract it into `data` directory (this process may take some time!):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "if not os.path.exists('data/PetImages'):\r\n",
    "    with zipfile.ZipFile('data/kagglecatsanddogs_3367a.zip', 'r') as zip_ref:\r\n",
    "        zip_ref.extractall(path='data')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(os.path.exists('data/PetImages/Cat'))\r\n",
    "print(os.path.exists('data/PetImages/Dog'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "std_normalize = transforms.Normalize(\r\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.244, 0.225])\r\n",
    "\r\n",
    "trans = transforms.Compose([\r\n",
    "    transforms.Resize(256),\r\n",
    "    transforms.CenterCrop(224),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    std_normalize\r\n",
    "\r\n",
    "])\r\n",
    "\r\n",
    "dataset = torchvision.datasets.ImageFolder('data/PetImages', transform=trans)\r\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [20000, len(dataset)-20000]) \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## Pre-trained model\r\n",
    "\r\n",
    "vgg = torchvision.models.vgg16(pretrained=True)\r\n",
    "sample_image = dataset[0][0].unsqueeze(0)\r\n",
    "res = vgg(sample_image)\r\n",
    "class_map = json.loads(requests.get(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\").text)\r\n",
    "class_map = { int(k) : v for k,v in class_map.items() }\r\n",
    "\r\n",
    "class_map[res[0].argmax().item()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "summary(vgg,input_size=(1,3,224,224))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchinfo\\torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m                 \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 1, 224, 224] to have 3 channels, but got 1 channels instead",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e21dcfd71dbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchinfo\\torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     )\n\u001b[1;32m--> 191\u001b[1;33m     summary_list = forward_pass(\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchinfo\\torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mexecuted_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         raise RuntimeError(\n\u001b[0m\u001b[0;32m    268\u001b[0m             \u001b[1;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition to the layer we already know, there is also another layer type call Dropout. These layers act as **regularization** technique. Regularization makes slight modifications to the learning proportion (around 30%) of the neurons in the previous layer, and training happens without them. This helps to get the optimization process out of local minima, and to distribute decisive power between different neural paths, which improves overall stability of the network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU computations\r\n",
    "\r\n",
    "Deep neural networks, such as VGG-16 and other more modern architectures require quite a lot of computational power to run. It makes sense to use GPU acceleration, if it is available. In order to do so, we need to explicitly move all tensors involved in the computation to GPU.\r\n",
    "\r\n",
    "The way it is normally done is to check the availability of GPU in the code, and define `device` variable that points to the computational device - either GPU or CPU.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "print('Doing computations on device = {}'.format(device))\r\n",
    "\r\n",
    "vgg.to(device)\r\n",
    "sample_image = sample_image.to(device)\r\n",
    "\r\n",
    "vgg(sample_image).argmax()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Doing computations on device = cuda\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(281, device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting VGG features\r\n",
    "\r\n",
    "If we want to use VGG-16 to extract features from our images, we need the model without final classification layers. In fact, this \"feature extractor\" can be obtained using **vgg.features** method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res = vgg.features(sample_image).cpu()\r\n",
    "plt.figure()\r\n",
    "plt.imshow(res.detach().view(-1,512))\r\n",
    "print(res.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 512, 7, 7])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dimension of feature is 512x7x7, but in order to visualize it we had to reshape it to 2D form. \r\n",
    "\r\n",
    "Let's try to see if those features can be used to classify images. Let's manually take some portion of image(800 in our case), and pre-compute their feature vectors. We will store the result in one big tensor called **feature_tensor**, and also labels into **label_tensor**:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bs = 8\r\n",
    "dl = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True)\r\n",
    "num = bs*100\r\n",
    "feature_tensor = torch.zeros((num, 512*7*7)).to(device)\r\n",
    "label_tensor = torch.zeros(num).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i = 0\r\n",
    "for x,l in dl:\r\n",
    "    with torch.no_grad():\r\n",
    "        f = vgg.features(x.to(device))\r\n",
    "        feature_tensor[i: i+bs] = f.view(bs,-1)\r\n",
    "        label_tensor[i:i+bs] = l\r\n",
    "        i+= bs\r\n",
    "        print('.', end='')\r\n",
    "        if i >= num:\r\n",
    "            break\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...................................................................................................."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vgg_dataset = torch.utils.data.TensorDataset(feature_tensor, label_tensor.to(torch.long))\r\n",
    "\r\n",
    "train_ds, test_ds = torch.utils.data.random_split(vgg_dataset, [700, 100])\r\n",
    "\r\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32)\r\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=32)\r\n",
    "\r\n",
    "net = nn.Sequential(nn.Linear(512*7*7,2), nn.LogSoftmax(dim=1)).to(device)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def training_epoch(model, dataloader, loss_fn, optimizer):\r\n",
    "    total_loss, acc = 0,0\r\n",
    "    data_size = len(dataloader.dataset)\r\n",
    "    for (X,y) in dataloader:\r\n",
    "        (X,y) = (X.to(device), y.to(device))\r\n",
    "        out = model(X)\r\n",
    "        loss = loss_fn(out, y)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        _, y_pred = torch.max(out, dim=1)\r\n",
    "        total_loss += loss_fn(out, y).item()\r\n",
    "        acc += (y_pred == y).type(torch.float).sum().item()\r\n",
    "    return total_loss/(data_size), acc/(data_size)\r\n",
    "\r\n",
    "def valid_epoch(model, dataloader, loss_fn):\r\n",
    "    data_size = len(dataloader.dataset)\r\n",
    "    loss, acc = 0,0\r\n",
    "    model.eval()\r\n",
    "    for X,y in dataloader:\r\n",
    "        X,y = X.to(device), y.to(device)\r\n",
    "        out = model(X)\r\n",
    "        _, y_pred = torch.max(out, dim=1)\r\n",
    "        loss += loss_fn(out, y).item()\r\n",
    "        acc += (y_pred == y).type(torch.float).sum().item()\r\n",
    "        \r\n",
    "    return loss/(data_size), acc/(data_size)\r\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_hist = []\r\n",
    "test_hist = []\r\n",
    "for t in range(3):\r\n",
    "    train_hist.append(training_epoch(net, train_loader, loss_fn, optimizer))\r\n",
    "    with torch.no_grad():\r\n",
    "        test_hist.append(valid_epoch(net, test_loader, loss_fn))\r\n",
    "train_loss = [i[0] for i in train_hist]\r\n",
    "train_acc = [i[1] for i in train_hist]\r\n",
    "test_loss = [i[0] for i in test_hist]\r\n",
    "test_acc = [i[1] for i in test_hist]\r\n",
    "\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "plt.plot([x+1 for x in range(3)], train_acc)\r\n",
    "plt.plot([x+1 for x in range(3)], test_acc)\r\n",
    "plt.legend(['train_acc', 'test_acc'])\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(vgg)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see that the network contains:\r\n",
    "* feature extractor (`features`), comprised of a number of convolutional and pooling layers\r\n",
    "* average pooling layer (`avgpool`)\r\n",
    "* final `classifier`, consisting of several dense layers, which turns 25088 input features into 1000 classes (which is the number of classes in ImageNet)\r\n",
    "\r\n",
    "To train the end-to-end model that will classify our dataset, we need to:\r\n",
    "* **replace the final classifier** with the one that will produce required number of classes. In our case, we can use one `Linear` layer with 25088 inputs and 2 output neurons.\r\n",
    "* **freeze weights of convolutional feature extractor**, so that they are not trained. It is recommended to initially do this freezing, because otherwise untrained classifier layer can destroy the original pre-trained weights of convolutional extractor. Freezing weights can be accomplished by setting `requires_grad` property of all parameters to `False`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vgg.classifier = torch.nn.Linear(25088,2).to(device)\r\n",
    "for x in vgg.features.parameters():\r\n",
    "    x.requires_grad = False\r\n",
    "\r\n",
    "summary(vgg,(1, 3,244,244))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VGG                                      --                        --\n",
       "├─Sequential: 1-1                        [1, 512, 7, 7]            --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 244, 244]         (1,792)\n",
       "│    └─ReLU: 2-2                         [1, 64, 244, 244]         --\n",
       "│    └─Conv2d: 2-3                       [1, 64, 244, 244]         (36,928)\n",
       "│    └─ReLU: 2-4                         [1, 64, 244, 244]         --\n",
       "│    └─MaxPool2d: 2-5                    [1, 64, 122, 122]         --\n",
       "│    └─Conv2d: 2-6                       [1, 128, 122, 122]        (73,856)\n",
       "│    └─ReLU: 2-7                         [1, 128, 122, 122]        --\n",
       "│    └─Conv2d: 2-8                       [1, 128, 122, 122]        (147,584)\n",
       "│    └─ReLU: 2-9                         [1, 128, 122, 122]        --\n",
       "│    └─MaxPool2d: 2-10                   [1, 128, 61, 61]          --\n",
       "│    └─Conv2d: 2-11                      [1, 256, 61, 61]          (295,168)\n",
       "│    └─ReLU: 2-12                        [1, 256, 61, 61]          --\n",
       "│    └─Conv2d: 2-13                      [1, 256, 61, 61]          (590,080)\n",
       "│    └─ReLU: 2-14                        [1, 256, 61, 61]          --\n",
       "│    └─Conv2d: 2-15                      [1, 256, 61, 61]          (590,080)\n",
       "│    └─ReLU: 2-16                        [1, 256, 61, 61]          --\n",
       "│    └─MaxPool2d: 2-17                   [1, 256, 30, 30]          --\n",
       "│    └─Conv2d: 2-18                      [1, 512, 30, 30]          (1,180,160)\n",
       "│    └─ReLU: 2-19                        [1, 512, 30, 30]          --\n",
       "│    └─Conv2d: 2-20                      [1, 512, 30, 30]          (2,359,808)\n",
       "│    └─ReLU: 2-21                        [1, 512, 30, 30]          --\n",
       "│    └─Conv2d: 2-22                      [1, 512, 30, 30]          (2,359,808)\n",
       "│    └─ReLU: 2-23                        [1, 512, 30, 30]          --\n",
       "│    └─MaxPool2d: 2-24                   [1, 512, 15, 15]          --\n",
       "│    └─Conv2d: 2-25                      [1, 512, 15, 15]          (2,359,808)\n",
       "│    └─ReLU: 2-26                        [1, 512, 15, 15]          --\n",
       "│    └─Conv2d: 2-27                      [1, 512, 15, 15]          (2,359,808)\n",
       "│    └─ReLU: 2-28                        [1, 512, 15, 15]          --\n",
       "│    └─Conv2d: 2-29                      [1, 512, 15, 15]          (2,359,808)\n",
       "│    └─ReLU: 2-30                        [1, 512, 15, 15]          --\n",
       "│    └─MaxPool2d: 2-31                   [1, 512, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [1, 512, 7, 7]            --\n",
       "├─Linear: 1-3                            [1, 2]                    50,178\n",
       "==========================================================================================\n",
       "Total params: 14,764,866\n",
       "Trainable params: 50,178\n",
       "Non-trainable params: 14,714,688\n",
       "Total mult-adds (G): 17.99\n",
       "==========================================================================================\n",
       "Input size (MB): 0.71\n",
       "Forward/backward pass size (MB): 128.13\n",
       "Params size (MB): 59.06\n",
       "Estimated Total Size (MB): 187.91\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see from the summary, this model contain around 15 million total parameters, but only 50k of them are trainable - those are the weights of classification layer. That is good, because we are able to fine-tune smaller number of parameters with smaller number of examples.\r\n",
    "\r\n",
    "Now let's train the model using our original dataset. This process will take a long time, so we will use `train_long` function that will print some intermediate results without waiting for the end of epoch. It is highly recommended to run this training on GPU-enabled compute!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "b8476f40adbb31d316263111a5645b453d35d3e96db58041b0655f021c3b1406"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}